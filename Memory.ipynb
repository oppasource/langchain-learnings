{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae3bb4a",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "This notebook explains different types of memory that can be used in langchain to maintain context in conversations while bulding a chatbot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ba5aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f1f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df49f1a",
   "metadata": {},
   "source": [
    "### Conversation Buffer Memory\n",
    "\n",
    "Keeps all the memory intact, this could insrease the token usage for long conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa884c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4471c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fb0dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"whats my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb225b",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"tell a joke on fruits, while you do that remember that my friends call me Yash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0714aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"whats my name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87703529",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23032b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301f124d",
   "metadata": {},
   "source": [
    "### Conversation Buffer Window Memory\n",
    "\n",
    "Trims the conversation based on the window size (conversation turns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5debce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8df18",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferWindowMemory(k=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1ae356",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"my name is Yash\"},\n",
    "                    {\"output\": \"noted\"})\n",
    "memory.save_context({\"input\": \"and my dog's name is Hash\"},\n",
    "                    {\"output\": \"noted\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a933f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e114e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0)\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae58129",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"my name is Yash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8785b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"and my dog's name is Hash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c839a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"whats my name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500a31d5",
   "metadata": {},
   "source": [
    "### Conversation Token Buffer Memory\n",
    "\n",
    "Crops the conversation if it exceeds the provided max token limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "from langchain.llms import OpenAI\n",
    "llm = ChatOpenAI(temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232568fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationTokenBufferMemory(llm=llm, max_token_limit=30)\n",
    "memory.save_context({\"input\": \"what is dogs + cats\"},\n",
    "                    {\"output\": \"cant add\"})\n",
    "memory.save_context({\"input\": \"bananas + mangoes?\"},\n",
    "                    {\"output\": \"cant add\"})\n",
    "memory.save_context({\"input\": \"1 + 1\"}, \n",
    "                    {\"output\": \"can add, 2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c33715",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc93769",
   "metadata": {},
   "source": [
    "### Conversation Summary Buffer Memory\n",
    "\n",
    "Summarizes the conversation if it exceeds the provided max token limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7247a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59725d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headphones_info = \"I love the XYZ Brand wireless headphones! \\\n",
    "They have a sleek design, comfortable fit, \\\n",
    "and impressive sound quality. \\\n",
    "The wireless connectivity and long battery life add to the convenience. \\\n",
    "Although the touch controls can be sensitive, overall, \\\n",
    "these headphones are a top recommendation for their excellent performance and freedom.\"\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=40)\n",
    "memory.save_context({\"input\": \"Hello\"}, {\"output\": \"What's up\"})\n",
    "memory.save_context({\"input\": \"Not much, just hanging\"},\n",
    "                    {\"output\": \"Cool\"})\n",
    "memory.save_context({\"input\": \"Tell me about XYZ wireless headphone?\"}, \n",
    "                    {\"output\": f\"{headphones_info}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d54901",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f5e163",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation = ConversationChain(\n",
    "    llm=llm, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6300cbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation.predict(input=\"my friend asked me which headphones she can buy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647b765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ac2ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb704ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021180ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb04347",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e307d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
