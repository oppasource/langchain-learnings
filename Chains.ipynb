{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7c9168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b005f585",
   "metadata": {},
   "source": [
    "## LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071a208d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Suggest movies of the following genre: {genre}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ea753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = \"comedy\"\n",
    "print(chain.run(genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e04dd2d",
   "metadata": {},
   "source": [
    "## SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b2268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6033c588",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Suggest movies of the following genre: {genre}\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6efe701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words review for the following \\\n",
    "    movies:{movie_names}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744c1ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210def51",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 'comedy'\n",
    "print(overall_simple_chain.run(genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99081e8f",
   "metadata": {},
   "source": [
    "## SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b45f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1c7973",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9)\n",
    "\n",
    "# prompt template 1: get movie names from genre\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Suggest 2 movies of the following genre: {genre}\"\n",
    ")\n",
    "# chain 1: input= genre and output= movie_names\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt, \n",
    "                     output_key=\"movie_names\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a169d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2: generating cast of movies\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Give cast of the following movies: {movie_names}\"\n",
    ")\n",
    "# chain 2: input= movie_names and output= cast\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt, \n",
    "                     output_key=\"cast\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b9db5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: generating reviews of movies\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words review for the following \\\n",
    "    movies:{movie_names}\"\n",
    ")\n",
    "# chain 3: input= movie_names and output= reviews\n",
    "chain_three = LLMChain(llm=llm, prompt=third_prompt,\n",
    "                       output_key=\"reviews\"\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe291ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: counting actors and actresses \n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Give count of actors and actresses in each movie from its cast list: {cast}\"\n",
    ")\n",
    "# chain 4: input= cast, language and output= cast_count\n",
    "chain_four = LLMChain(llm=llm, prompt=fourth_prompt,\n",
    "                      output_key=\"cast_count\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d6ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= genre \n",
    "# and output= cast, reviews, cast_count\n",
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables=[\"genre\"],\n",
    "    output_variables=[\"cast\", \"reviews\",\"cast_count\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defdcedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre = 'comedy'\n",
    "print(overall_chain(genre))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aed322",
   "metadata": {},
   "source": [
    "## RouterChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273ffc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1390ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9b8b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_purchase_template = \"\"\"You are a very smart salesman. \\\n",
    "You have only one goal that is to try and get customers to buy products from you.\\\n",
    "Whenever customer asks about any product, you describe the product in such a way that they cant resist.\\\n",
    "Even when customer is confused ot dose not know what to buy, you describe about your products do that it sells.\\\n",
    "All this but at the same time dont let the customer know you are talking as a salesman.\\\n",
    "\n",
    "Here is a question that customer is asking:\\\n",
    "{input}\"\"\"\n",
    "\n",
    "post_purchase_template = \"\"\"You are handling cutomers who have post-purchase queries.\\\n",
    "You will keep the answers short, to the point and crsip so that customer feels satisfed.\\\n",
    "You may also try and retain the customers so they place repeat orders.\\\n",
    "You can give them some offer as well if you think that will help in customer to re-order.\\\n",
    "\n",
    "Here is a question that customer is asking:\\\n",
    "{input}\"\"\"\n",
    "\n",
    "angry_customer_template = \"\"\"You are dealing with an angry customer for some reason.\\\n",
    "You have to give a very poliet and sweet reply back and also be apologetic if needed.\\\n",
    "You will try and calm the customer and assure them about resolution.\\\n",
    "\n",
    "Here is a question that customer is asking:\\\n",
    "{input}\"\"\"\n",
    "\n",
    "default_template = \"\"\" You are a customer service agent at an e-commerce.\\\n",
    "You handle any random questions that user may ask which is not realted to our business.\\\n",
    "You may answer the user in a very short manner or you if you think you can deny answering as well\\\n",
    "as we dont want to entertain much of the customer queries which are unrelated.\\\n",
    "\n",
    "Here is a question that customer is asking:\\\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3432d5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"pre_purchase\", \n",
    "        \"description\": \"Good for pushing products to customer for selling when customers are in pre-purchase phase.\", \n",
    "        \"prompt_template\": pre_purchase_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"post_purchase\", \n",
    "        \"description\": \"Good for answering post-purchase queries to customers in to the point and a crisp manner.\", \n",
    "        \"prompt_template\": post_purchase_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"angry_customer\", \n",
    "        \"description\": \"Good for talking polietly to customer with apologizing attitude.\", \n",
    "        \"prompt_template\": angry_customer_template\n",
    "    } \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed17b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "for p_info in prompt_infos:\n",
    "    name = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08dc7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_prompt = ChatPromptTemplate.from_template(default_template)\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c83ceef",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \\\n",
    "language model select the model prompt best suited for the input. \\\n",
    "You will be given the names of the available prompts and a \\\n",
    "description of what the prompt is best suited for. \\\n",
    "You may also revise the original input if you think that revising\\\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt strcitly \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json in proper mardown format even if destination is DEFAULT)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2608a611",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22e74b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(router_chain=router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain=default_chain, verbose=True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f453c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"where the hell is my order, its been 2 weeks now. I want my money back right now\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213fc5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"Is your product acne clear a good cream? I heard it has lots of side effects\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560a118",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"i want to track my order\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd728d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"what is bitcoin\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211a8605",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chain.run(\"what colour dress are you wearing?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1625793e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf4484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27db3f8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49a0867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f50aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b084b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ed854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c823a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
